{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summaries for SCADS Application \n",
    "\n",
    "Utilizing Occams to build single document summaries for SCADS Demo application use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "import multisum as msu\n",
    "import re\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data from sqlite file\n",
    "# resources: https://datacarpentry.org/python-ecology-lesson/09-working-with-sql/index.html\n",
    "con = sqlite3.connect(\"data_large/news (1).sqlite\")\n",
    "\n",
    "# use this to check schema details and table names\n",
    "# cur = con.cursor()\n",
    "# cur.execute('SELECT * FROM sqlite_master')\n",
    "# cur.fetchall()\n",
    "\n",
    "df = pd.read_sql_query(\"SELECT * FROM article\", con)\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: The database does not have the text from the article... boo. Merging values based on nid together.\n",
    "# This dataset has scrapped the article text from the URL in 'efs/home/strotto/MIND HTML Pre-Processing.ipynb'\n",
    "MIND_w_topics=pd.read_csv(\"~/efs/home/pcorona_content/MIND_Train_w_Topics.csv\")\n",
    "MIND_w_topics.sort_values(by=['Title', '_score_'], ascending=False, inplace=True)\n",
    "MIND_w_topics.drop_duplicates(subset=['Title'], keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = df.merge(MIND_w_topics, how='left', left_on='title', right_on='Title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sum = dff[~dff['Text'].isna()].reset_index()[['nid', 'cat', 'subcat', 'Title', 'abstract', 'display_date', 'Text']]\n",
    "to_sum['summary'] = ''\n",
    "to_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through all texts to summarize \n",
    "for ele in tqdm(range(0, len(to_sum))):\n",
    "    documents, doc_incidences, load_time = msu.load_corpus(to_sum.loc[ele:ele].reset_index(), 'Text')\n",
    "    # preprocessing occurs here, removing starting phrases and URLs\n",
    "    a = [x.text for x in documents[0].sentences if not bool(re.match(\"[A-Z]+( |:|-){1}\", str(x.text))) and not bool(re.match('(.*)(\\.com|\\.edu|\\.net|\\.org)', str(x.text)))]\n",
    "    to_sum['Text'][ele] = \" \".join(a)\n",
    "    documents, doc_incidences, load_time = msu.load_corpus(to_sum.loc[ele:ele].reset_index(), 'Text')\n",
    "\n",
    "    # if only 1 sentance has been recognized, then don't allow for summarization \n",
    "    if len(documents[0].sentences) > 1:\n",
    "        # summarizing with scheme \"sentences\", of length \"300\"\n",
    "        build_time, extract_time, sentences, doc_titles_new, extractor, sentence_weights = msu.summarize_collect(to_sum.loc[ele:ele].reset_index(), documents, doc_incidences, 'sentances', 300, False)\n",
    "        summary_text = [sentences[x].text for x in range(0, len(sentences))]\n",
    "    else: \n",
    "        summary_text = 'Summary Not Available'\n",
    "        \n",
    "    to_sum['summary'][ele] = summary_text\n",
    "\n",
    "to_sum.rename(columns = {'Title': 'title', 'Text':'text'}, inplace=True)\n",
    "to_sum.to_csv(\"out/sumSCADS_v3.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_sum['summary'] = [None if x == '' or x == [] or x == 'Summary Not Available' else x for x in to_sum['summary']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export data back to sqllite file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep the original data (even if it doesn't have a summary)\n",
    "wdf = df.merge(to_sum[['nid', 'summary']], how='left', left_on='nid', right_on='nid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn array into string w/ unique delimiter \n",
    "wdf['sum'] = [\" | \".join(x) if type(x) == list else None for x in wdf['summary']]\n",
    "wdf = wdf[['nid', 'cat', 'subcat', 'title', 'abstract', 'display_date', 'sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.connect(\"data_large/news (1).sqlite\")\n",
    "\n",
    "# Write the new DataFrame to a new SQLite table\n",
    "wdf.to_sql(\"articlesSum\", con, if_exists=\"replace\", index=False)\n",
    "\n",
    "con.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "occams3.7",
   "language": "python",
   "name": "occams3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c35f7f4fba3e06d1ea9a7fd2d8894efc0e475ab60feefc8a043db9f67392eaee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
